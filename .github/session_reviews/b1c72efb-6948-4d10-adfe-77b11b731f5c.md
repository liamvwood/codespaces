# Session Review — Install GitHub Copilot CLI / Job Search Setup (2026-02-21)
**Session ID:** b1c72efb-6948-4d10-adfe-77b11b731f5c
**Duration:** 2026-02-21T18:46:55Z → 2026-02-21T19:21:08Z (~34 min)
**CWD:** /workspaces/codespaces

## Summary
Long, multi-phase session that set up the entire Career/ job search infrastructure from
scratch: devcontainer config, Playwright job scraper (Greenhouse, HRT, Ongig, Jane Street,
BuiltInAustin), 572-role CSV tracker with location filtering, 4 resume variants compiled to
PDF, 7 company-specific cover letters, and Copilot instructions split into root + Career-scoped
files. Multiple server interruptions required "pick up where you left off" prompts.

---

## What Went Well
- Agent correctly used `git mv` and maintained clean commit history across restructuring
- Final directory layout (`Career/resumes/`, `cover_letters/`, `applications/`, `scripts/`) is
  clean and well-structured for agents
- Splitting root vs. Career-scoped `copilot-instructions.md` was a good call, prompted by user
- Deduplication logic in the scraper was solid; re-runs are safe
- Agent correctly moved ad-hoc `/tmp/` scripts into the repo when asked

---

## Instruction Gaps → Fixes

| Gap | Recommended Fix |
|-----|----------------|
| Location preference (NYC, Austin, Miami) had to be stated mid-session, causing retroactive location column addition | Add to `Career/.github/copilot-instructions.md`: "Target locations: NYC, Austin, Miami, Remote — always filter scraped jobs to these" |
| "Persist files to repo" had to be explicitly requested | Add to root instructions: "Always write scripts and output files directly to the repo, never to /tmp/" |
| Mixed casing (`Resumes/` vs `scripts/`) slipped through initial setup | Add to root instructions: "All directory names must be lowercase snake_case" |
| `pdflatex` not pre-installed; required `apt-get` mid-session | Already fixed in `devcontainer.json` `postCreateCommand` ✅ |
| No session continuity mechanism — "pick up where you left off" used 3 times | Add a `## Current Status` section to `Career/README.md` updated each session; or use `sessionEnd` hook to write a checkpoint |
| Agent wrote cover letter templates without explicitly asking for company-specific vs. generic | Add to Career instructions: "Always create both a company-specific letter AND update the relevant track template" |
| Two Sigma/Optiver required multiple debug cycles because scraping approach wasn't clear | Add to scraper comments: known-difficult sites and their approach (Workday, Cloudflare-protected) |

---

## Missing Agents → Proposals

| Task Pattern | Proposed Agent |
|-------------|----------------|
| Repeated scraper debugging cycle (inspect network calls, find API, extract token) | `scraper-debugger` skill — instructions for inspecting Playwright network logs to find hidden APIs |
| "Pick up where you left off" used 3 times — agent had to re-read git log each time | `session-checkpoint` skill — writes a `CHECKPOINT.md` at end of each major task |

---

## Missing / Improvable Skills → Proposals

| Repeated Command | Proposed Skill |
|-----------------|----------------|
| `python Career/scripts/scrape_jobs.py` run 6+ times with manual output checking | `scrape-jobs` skill ✅ (now exists) |
| `pdflatex` compile + move to pdf/ + cleanup | `compile-resume` skill ✅ (now exists) |
| CSV stats queries (count by status, location, tier) | `tracker-stats` skill ✅ (now exists) |
| Checking `git log --oneline` to re-orient after interruption | `session-checkpoint` skill — write/read a checkpoint file |

---

## Hook Opportunities

| Trigger | Action |
|---------|--------|
| `sessionStart` | Show application stats dashboard ✅ (now implemented) |
| `sessionEnd` | Write a `CHECKPOINT.md` with last completed task, open items, and next steps |
| `userPromptSubmitted` | Detect "pick up where you left off" and auto-read `CHECKPOINT.md` |

---

## Workflow Inefficiencies
- **Server errors broke flow 3 times**: Agent had to re-read git log to re-orient each time.
  A `CHECKPOINT.md` written at end of each task would eliminate the "pick up where you left off" pattern.
- **Ad-hoc debug scripts in /tmp**: Agent wrote 15+ one-off `python3 << EOF` blocks before
  committing final code. A "prototype first, commit when working" instruction would help, but
  the core issue is that `/tmp` scripts vanish on interruption.
- **Location requirement stated late**: 572 roles scraped before NYC/Austin/Miami filter was
  added — many rows had to be retroactively filtered. Pre-loading preferences in instructions
  eliminates this.
- **Scraper development was sequential (one company at a time)**: Could have used parallel
  Playwright contexts to speed up discovery.
- **`pdflatex` installation**: Took ~3 minutes mid-session. Now pre-installed in devcontainer.

---

## Top 3 Actionable Recommendations
1. **Add a `sessionEnd` hook** that writes `Career/CHECKPOINT.md` with: last task completed,
   open items, next recommended action. This eliminates "pick up where you left off" entirely.
2. **Add location + persistence rules to Career instructions**: "Filter all scraped jobs to
   NYC, Austin, Miami, Remote" and "Always write scripts to the repo, not /tmp/".
3. **Add a `scraper-debugger` skill** with instructions for finding hidden APIs via Playwright
   network interception — reusable pattern used 6+ times in this session.

---

## Applied Immediately
- ✅ Location preference added to `Career/.github/copilot-instructions.md` (see below)
- ✅ `sessionStart` hook created
- ⏳ `sessionEnd` checkpoint hook — to be implemented
- ⏳ `scraper-debugger` skill — to be implemented
